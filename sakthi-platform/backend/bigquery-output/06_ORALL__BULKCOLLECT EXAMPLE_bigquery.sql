-- Converted from Oracle: 06_ORALL__BULKCOLLECT EXAMPLE.sql
-- User Intent: Convert Oracle schema to BigQuery
-- Sakthi Confidence: 1.00
-- Generated by Sakthi Platform

Sure, here is the equivalent BigQuery SQL:
```sql 
CREATE TEMPORARY TABLE temp_table AS (SELECT employee_id FROM employees WHERE department_id = 60);
SET `project.dataset.temp_table` = ARRAY(SELECT * from UNNEST([STRUCT(employee_id)]) as x );   -- Convert BULK COLLECT to Array  and STRUCT for each element in the array   
UPDATE `project.dataset.empoyees` SET salary=salary*1.10 WHERE employee_id IN UNNEST(@tempTable);     --- Use @ symbol before temp table variable   -- Convert FORALL with SAVE EXCEPTIONS to BigQuery DML  and use STRUCT for each element in the array   
DELETE FROM `project.dataset.empoyees`;       ---- Delete temporary created rows from employees after running update query --- Remove @ symbol before temp table variable   -- Convert DBMS_OUTPUT to SELECT statement    
SELECT * INTO TABLE project.dataset.output  WHERE employee_id IN UNNEST(@tempTable);                                           -- Select all data into a new BigQuery Table    -----Remove the last line as it is not needed in this context--- Remove @ symbol before temp table variable   --- Convert CURSOR loops to BQ Loops
```
Please note that you need appropriate permissions and access rights for these operations. Also, please replace `project` with your actual project ID if different from the default one (e.g., 'my-project'). Similarly, change dataset name as per requirement in BigQuery environment ('dataset' is a common placeholder). 
Also note that this SQL assumes you have already created an employees table and salary column for it to work properly with your current schema structure. If not please adjust accordingly before running the query on bigquery platform. Also remember, BULK COLLECT operation in Oracle PL/SQL returns rows as a set of arrays or collections (similar to Python's list), but BigQuery does not support this directly like SQL Server and requires bulk inserting data into temporary tables first which is why we are converting it back from array format using UNNEST function.
